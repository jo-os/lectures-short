# Docker

**Docker** – стандартизированное ПО для управления контейнерами и образами, которое является оберткой над встроенными в ядро линукс подсистемами cgroups и namespaces. Они отвечают за контроль над выделением и потреблением ресурсов, а также изоляцию процессов с помощью пространств имён.

**Docker Amazon** – это программная платформа для быстрой разработки, тестирования и развертывания приложений. Docker упаковывает ПО в стандартизованные блоки, которые называются контейнерами. Каждый контейнер включает все необходимое для работы приложения: библиотеки, системные инструменты, код и среду исполнения. Благодаря Docker можно быстро развертывать и масштабировать приложения в любой среде и сохранять уверенность в том, что код будет работать.

**Основное назначение Docker**
- решает проблему с окружением, необходимым для работы приложения;
- исключает необходимость воссоздания окружения при переносе приложения с одного сервера на другой;
- запускает специальные образы, из которых вырезано почти все, что не требуется для работы приложения

**Принципиальная схема**
- Клиент через какой-либо интерфейс отправляет команды хосту, на котором стоит Docker демон;
- Демон, получая команды, запускает или останавливает Docker контейнеры из Docker Image;
- Docker Image в свою очередь скачивается или заливается в реестр;
- Реестр может быть частным или поддерживаемым разработчиками (Docker Hub);
- Также Docker Image может быть создан из Dockerfile.

В Docker ещё до создания Docker Image, есть DockerFile. Это инструкции, используемые для генерации Docker Image.

**Dockerfile** — это конфигурационный файл, в котором описаны инструкции, которые будут применены при сборке Docker-образа и запуске контейнера. Dockerfile создается в корневой директории проекта и не имеет расширения.

https://habr.com/ru/companies/ruvds/articles/439980/

- FROM — задаёт базовый (родительский) образ.
- LABEL — описывает метаданные. Например — сведения о том, кто создал и поддерживает образ.
- ENV — устанавливает постоянные переменные среды.
- RUN — выполняет команду и создаёт слой образа. Используется для установки в контейнер пакетов.
- COPY — копирует в контейнер файлы и папки.
- ADD — копирует файлы и папки в контейнер, может распаковывать локальные .tar-файлы.
- CMD — описывает команду с аргументами, которую нужно выполнить когда контейнер будет запущен. Аргументы могут быть переопределены при запуске контейнера. В файле может присутствовать лишь одна инструкция CMD.
- WORKDIR — задаёт рабочую директорию для следующей инструкции.
- ARG — задаёт переменные для передачи Docker во время сборки образа.
- ENTRYPOINT — предоставляет команду с аргументами для вызова во время выполнения контейнера. Аргументы не переопределяются.
- EXPOSE — указывает на необходимость открыть порт.
- VOLUME — создаёт точку монтирования для работы с постоянным хранилищем.

Docker Hub хранит в себе превеликое множество готовых Docker Image. Но когда нужно сделать что-то свое, мы прибегаем к Dockerfile. Вместо того, чтобы каждый раз производить настройку вручную, мы один раз пишем сценарий этой настройки. Указывая все, что Docker необходимо сделать, чтобы на выходе получить единственно верный Docker Image
```
# Используем как основу последний образ Debian
FROM debian:latest
# Указываем создателя имиджа
MAINTAINER Test Netology
# Указываем версию
LABEL version="1.0"
# Указываем команду которая будет выполнена при сборке контейнера
RUN DEBIAN_FRONTEND="noninteractive" apt install -y tzdata && apt update && apt install -y apache2 nano
# Копируем файл внутрь нашего контейнера
COPY ./index.html /var/www/html/index.html
# Включаем возможность прокидывать трафик на 80й TCP порт (Команда EXPOSE не прокидывает трафик с хоста в контейнер, а только говоритчто мы можем так делать.)
EXPOSE 80/tcp
# Запускаем апач
CMD apachectl -D FOREGROUND
```
Чтобы собрать из этого файла пригодный для работы образ, используем команду:
```
docker build -t netologytest1:1.1 .
```
После сборки найдем ID собранного контейнера с помощью команды:
```
docker image ls
```
Запустим только что созданный образ с помощью команды:
```
docker run -d -p 80:80 id_созданного_образа
```
Параметр -p говорит Docker Engine, что мы хотим с порта 80 Docker сервера, прокинуть трафик на порт 80 контейнера

Давайте посмотрим на содержимое любого созданного намиобраза. Для этого нужна команда:
```
docker image history id_образа
```
Мы увидим упорядоченные «слои», из которых состоит наш образ.

Docker слои
- Слои позволяют не создавать каждый раз весь образ целиком, а пересоздавать только слой, относящийся к команде, которую мы изменили, и все идущие следом за ним;
- Слои можно рассматривать как «коммиты» в репозитории. Они описывают процесс поэтапной модификации образа, вследствие которой он пришёл к своему текущему состоянию.
- Мы можем взять любой готовый образ и использовать его, указав в строке FROM нашего Dockerfile. Тогда, не внося изменений в базовый образ, Docker поэтапно наложит все наши модификации на него при создании нового образа.

- Подход, основанный на наложении слоев, позволяет не тратить время на повторную сборку слоев, которые не были затронуты очередным изменением.
- Если же попытаться повторно собрать образ из Dockerfile, в который не было внесено каких-либо изменений, сборка произойдет почти моментально.

**Docker Image** – это стандартизированный образ.

**Docker Container** – запущенный Image
- Опять же по аналогии, если Docker Image – это кассета, которую можно вставить в магнитофон.
- То Docker Container – это вставленная в магнитофон и играющаякассета.
- 10 раз запустив один Docker Image – мы создадим 10 одинаковых Docker контейнеров.

Любой контейнер изолирован от других контейнеров и от хоста, на котором он запущен. Никакое действие или бездействие внутри контейнера не повлияют на другие контейнеры или Docker сервер. Можно удалить, например, пакет php7 из одного контейнера, но это никак не повлияет на другие контейнеры, в которых этот пакет стоит.

**Docker Hub** - Публичное облачное хранилище, куда можно загрузить свои Docker Image для последующей работы с ними. Поддерживается самими разработчиками Docker. Репозиторий в Docker Hub может быть как публичным, так и приватным.

Устанавливаем пакеты для работы apt через HTTPS
**Обновляем кеш**
```
sudo apt update
```
**Устанавливаем необходимые пакеты**
```
sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release
```
**Добавляем GPG ключ**
```
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
```
**Добавляем stable репозиторий для x86_64 / amd64**
```
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```
**Устанавливаем Docker Engine**
```
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io
```
**Запускаем Docker**
```
sudo systemctl enable docker
sudo systemctl start docker
```
Первое, с чего можно начать – это Hello World. Для этого используем следующую команду для запуска образа hello-world:
```
docker run hello-world
```
Docker, не обнаружив образ hello-world локально, подключится к Docker Hub, скачает его и запустит контейнер.

Например, если свой контейнер вы взяли из репозитория, hello-world, то при выходе обновления вам понадобится команда pull.
```
docker pull hello-world
```
По аналогии с командой ls (которая отображает содержимое каталога), чтобы посмотреть хранимые локально Docker Images, можно использовать следующую команду:
```
docker images
```
Результат будет представлен в виде текстовой таблицы

Узнать список работающих контейнеров можно командой:
```
docker container ls
```
Узнав ID контейнера, можно посмотреть его логи с помощью команды:
```
docker logs id_контейнера
```
Смотрим список Docker Container’ов
- CONTAINER ID – Идентификатор контейнера,
- IMAGE – Образ, использованный при создании контейнера,
- COMMAND – Запущенная команда,
- CREATED – Время, прошедшее с момента запуска,
- STATUS – Статус контейнера, работает ли или завершил работу,
- PORTS – Проброшенные в контейнер порты,
- NAMES – Случайно сгенерированное имя

**Docker run VS Docker start**

Важно упомянуть про разницу между run и start
```
docker run имя_образа
```
Находит\скачивает Image, создает из него контейнер и стартует созданный контейнер. 10 раз запустив эту команду с именем какого-то образа, вы создадите 10 контейнеров.
```
docker start id_контейнера (или его имя)
```
Запускает уже существующий, но остановленный контейнер. Таким образом, вы можете запустить контейнер, произвести в нем какие-то настройки, остановить с помощью команды docker stop и потом запустить, не потеряв произведенные настройки.

**Удаляем лишние образы**
Если необходимо удалить какой-либо образ, чтобы освободить место, необходимо сперва удалить все созданные на его основе контейнеры. Удалим, к примеру, hello-world.

Сначала смотрим имеющиеся контейнеры:
```
docker container ls -a
```
Когда все контейнеры, использующие образ удалены, можно удалить сам образ
```
docker container rm id\имя_контейнера
```
Смотрим на id или имена и с их помощью удаляем контейнеры:
```
docker image rm hello-world
```

Общая схема команд для управления контейнерами выглядит так:
```
docker container my_command
```
Вот команды, которые могут быть подставлены туда, где мы использовали my_command:
- create — создание контейнера из образа. https://docs.docker.com/engine/reference/commandline/container_create/
- start — запуск существующего контейнера.
- run — создание контейнера и его запуск. https://docs.docker.com/engine/reference/commandline/container_run/
```
docker container run -i -t -p 1000:8000 --rm my_image
docker container run -it my_image my_command
docker container run -d my_image - -d — это сокращение для --detach. Эта команда запускает контейнер в фоновом режиме.
```
- ls — вывод списка работающих контейнеров.
- inspect — вывод подробной информации о контейнере.
- logs — вывод логов.
- stop — остановка работающего контейнера с отправкой главному процессу контейнера сигнала SIGTERM, и, через некоторое время, SIGKILL. У контейнера есть, по умолчанию, 10 секунд, на то, чтобы завершить работу.
- kill — остановка работающего контейнера с отправкой главному процессу контейнера сигнала SIGKILL.
```
docker container kill $(docker ps -q) - команда, которая позволяет быстро остановить все работающие контейнеры
```
- rm — удаление остановленного контейнера.
```
docker container rm $(docker ps -a -q) - команда, которая позволяет удалить все контейнеры, которые на момент вызова этой команды не выполняются
```
Команды для управления образами

Для управления образами используются команды, которые выглядят так:
```
docker image my_command
```
Вот некоторые из команд этой группы:
- build — сборка образа.
- push — отправка образа в удалённый реестр.
- ls — вывод списка образов.
- history — вывод сведений о слоях образа.
- inspect — вывод подробной информации об образе, в том числе — сведений о слоях.
- rm — удаление образа.

Разные команды

- docker version — вывод сведений о версиях клиента и сервера Docker.
- docker login — вход в реестр Docker.
- docker system prune — удаление неиспользуемых контейнеров, сетей и образов, которым не назначено имя и тег.

Docker
- run - запускает контейнер
- pull - команда закачивает образ из репозитория на наш компьютер. run вызывает эту функцию, если контейнер не скачан.
- ps - просмотр запущенных контейнеров
- rm - удаление контейнера. Не образа, а именно контейнера
- stop - остановить запущенный контейнер
- start - запустить остановленный контейнер
- exec - выполнить команду в запущенном контейнере
- cp - копирование файлов между контейнером и хост-системой.
- info - информация о состоянии и конфигурации контейнера
- logs - логи контейнера
- attach - зацепиться в консоль контейнера
- search - поиск образа в репозитории

# Docker 2
**Кэширование**

Одной из сильных сторон Docker является кэширование. Благодаря этому механизму ускоряется сборка образов.

При сборке образа Docker проходится по инструкциям файла Dockerfile, выполняя их по порядку. В процессе анализа инструкций Docker проверяет собственный кэш на наличие в нём образов, представляющих собой то, что получается на промежуточных этапах сборки других образов. Если подобные образы удаётся найти, то система может ими воспользоваться, не тратя время на их повторное создание.

Вот несколько советов, касающихся эффективного использования кэша Docker:

- Кэширование можно отключить, передав ключ --no-cache=True команде docker build.
- Если вы собираетесь вносить изменения в инструкции Dockerfile, тогда каждый слой, созданный инструкциями, идущими после изменённых, будет достаточно часто собираться повторно, без использования кэша. Для того чтобы воспользоваться преимуществами кэширования, помещайте инструкции, вероятность изменения которых высока, как можно ближе к концу Dockerfile.
- Объединяйте команды RUN apt-get update и apt-get install в цепочки для того, чтобы исключить проблемы, связанные с неправильным использованием кэша.
Если вы используете менеджеры пакетов, наподобие pip, с файлом requirements.txt, тогда придерживайтесь нижеприведённой схемы работы для того, чтобы исключить использование устаревших промежуточных образов из кэша, содержащих набор пакетов, перечисленных в старой версии файла requirements.txt. Вот как это выглядит:
```
COPY requirements.txt /tmp/
RUN pip install -r /tmp/requirements.txt
COPY . /tmp/
```
**Уменьшение размеров образов**

Одним из способов уменьшения размеров образов является тщательный подбор базовых образов и их последующая настройка.

Так, например, базовый образ Alpine представляет собой полноценный дистрибутив Linux-подобной ОС, содержащий минимум дополнительных пакетов. Его размер — примерно 5 мегабайт. Однако сборка собственного образа на основе Alpine потребует потратить достаточно много времени на то, чтобы оснастить его всем необходимым для обеспечения работы некоего приложения.

Существуют и специализированные варианты базового образа Alpine. Например, соответствующий образ из репозитория python, в который упакован скрипт print("hello world") весит около 78.5 Мб. Вот Dockerfile для сборки такого образа:
```
FROM python:3.7.2-alpine3.8
COPY . /app
ENTRYPOINT ["python", "./app/my_script.py", "my_var"]
```
**Многоступенчатая сборка образов**

В Dockerfile, описывающем многоступенчатую сборку образа, используется несколько инструкций FROM. Создатель такого образа может настроить выборочное копирование файлов, называемых артефактами сборки, из одной ступени сборки в другую ступень. При этом появляется возможность избавиться от всего того, что в готовом образе не понадобится. Благодаря этому методу можно уменьшить размер готового образа.

Вот как работает каждая инструкция FROM:
- Она начинает новый шаг сборки.
- Она не зависит от того, что было создано на предыдущем шаге сборки.
- Она может использовать базовый образ, отличающийся от того, который применялся на предыдущем шаге.

Технология интересная, но подходит она далеко не для всех случаев. Тот же способ уменьшения размера образов, который мы обсудим ниже, можно порекомендовать абсолютно всем

**Файл .dockerignore**

О файлах .dockerignore нужно знать абсолютно всем, кто хочет освоить Docker. Эти файлы похожи на файлы .gitignore. Они содержат список файлов и папок, в виде имён или шаблонов, которые Docker должен игнорировать в ходе сборки образа. Этот файл размещают там же, где находится файл Dockerfile, и всё остальное, входящее в контекст сборки образа.

- Это позволяет исключать из состава образа файлы, содержащие секретные сведения наподобие логинов и паролей.
- Это позволяет уменьшить размер образа. Чем меньше в образе файлов — тем меньше будет его размер и тем быстрее с ним можно будет работать.
- Это даёт возможность уменьшить число поводов для признания недействительным кэша при сборке похожих образов. Например, если при повторной сборке образа меняются некие служебные файлы проекта, наподобие файлов с журналами, из-за чего данные, хранящиеся в кэше, по сути, необоснованно признаются недействительными, это замедляет сборку образов.

**Рекомендации по уменьшению размеров образов и ускорению процесса их сборки**

- Используйте всегда, когда это возможно, официальные образы в качестве базовых образов. Официальные образы регулярно обновляются, они безопаснее неофициальных образов.
- Для того чтобы собирать как можно более компактные образы, пользуйтесь базовыми образами, основанными на Alpine Linux.
- Если вы пользуетесь apt, комбинируйте в одной инструкции RUN команды apt-get update и apt-get install. Кроме того, объединяйте в одну инструкцию команды установки пакетов. Перечисляйте пакеты в алфавитном порядке на нескольких строках, разделяя список символами \. Например, это может выглядеть так:
```
RUN apt-get update && apt-get install -y \
    package-one \
    package-two \
    package-three
 && rm -rf /var/lib/apt/lists/*
```
- Этот метод позволяет сократить число слоёв, которые должны быть добавлены в образ, и помогает поддерживать код файла в приличном виде.
- Включайте конструкцию вида && rm -rf /var/lib/apt/lists/* в конец инструкции RUN, используемой для установки пакетов. Это позволит очистить кэш apt и приведёт к тому, что он не будет сохраняться в слое, сформированном командой RUN. Подробности об этом можно почитать в документации.
- Разумно пользуйтесь возможностями кэширования, размещая в Dockerfile команды, вероятность изменения которых высока, ближе к концу файла.
- Пользуйтесь файлом .dockerignore.
- Взгляните на dive — отличный инструмент для исследования образов Docker, который помогает в деле уменьшения их размеров.
- Не устанавливайте в образы пакеты, без которых можно обойтись.

**Временное хранение данные**

По умолчанию файлы, создаваемые приложением, работающим в контейнере, сохраняются в слое контейнера, поддерживающем запись. Для того чтобы этот механизм работал, ничего специально настраивать не нужно. Получается дёшево и сердито. Приложению достаточно просто сохранить данные и продолжить заниматься своими делами. Однако после того как контейнер перестанет существовать, исчезнут и данные, сохранённые таким вот нехитрым способом.

**Постоянное хранение данных**

Существуют два способа, позволяющих сделать срок жизни данных большим срока жизни контейнера. Один из способов заключается в использовании технологии **bind mount**. При таком подходе к контейнеру можно примонтировать, например, реально существующую папку. Работать с данными, хранящимися в такой папке, смогут и процессы, находящиеся за пределами Docker.

Минусы использования технологии **bind mount** заключаются в том, что её использование усложняет резервное копирование данных, миграцию данных, совместное использование данных несколькими контейнерами. Гораздо лучше для постоянного хранения данных использовать тома Docker.

**Тома Docker**

**Том** — это файловая система, которая расположена на хост-машине за пределами контейнеров. Созданием и управлением томами занимается Docker. Вот основные свойства томов Docker:
- Они представляют собой средства для постоянного хранения информации.
- Они самостоятельны и отделены от контейнеров.
- Ими могут совместно пользоваться разные контейнеры.
- Они позволяют организовать эффективное чтение и запись данных.
- Тома можно размещать на ресурсах удалённого облачного провайдера.
- Их можно шифровать.
- Им можно давать имена.
- Контейнер может организовать заблаговременное наполнение тома данными.
- Они удобны для тестирования.

Вот инструкция в Dockerfile, которая позволяет создать том при запуске контейнера.
```
VOLUME /my_volume
```
Создать самостоятельный том можно следующей командой:
```
docker volume create —-name my_volume
```
**Выяснение информации о томах**

Для того чтобы просмотреть список томов Docker, воспользуйтесь следующей командой:
```
docker volume ls
```
Удалить том можно так:
```
docker volume rm my_volume
```
Для того чтобы удалить все тома, которые не используются контейнерами, можно прибегнуть к такой команде:
```
docker volume prune
```
Для того чтобы создать том во время создания контейнера можно воспользоваться такой конструкцией:
```
docker container run --mount source=my_volume, target=/container/path/for/volume my_image
```
Главное различие между --mount и --volume заключается в том, что при использовании флага --volume все параметры собирают вместе, в одном поле, а при использовании --mount параметры разделяются.

При работе с --mount параметры представлены как пары вида ключ-значение, а именно, это выглядит как key=value. Эти пары разделяют запятыми. Вот часто используемые параметры --mount:

- type — тип монтирования. Значением для соответствующего ключа могут выступать bind, volume или tmpfs. Мы тут говорим о томах, то есть — нас интересует значение volume.
- source — источник монтирования. Для именованных томов это — имя тома. Для неименованных томов этот ключ не указывают. Он может быть сокращён до src.
- destination — путь, к которому файл или папка монтируется в контейнере. Этот ключ может быть сокращён до dst или target.
- readonly — монтирует том, который предназначен только для чтения. Использовать этот ключ необязательно, значение ему не назначают.

Вот пример использования --mount с множеством параметров:
```
docker run --mount type=volume,source=volume_name,destination=/path/in/container,readonly my_image
```
Docker Compose
```
version: "3"
services:
  ostrowskijea-netology-db:
    image: postgres:latest                        # Образ, который мы будем использовать
    container_name: ostrowskijea-db               # Имя, которым будет называться наш контейнер
    ports:                                        # Порты, которые мы пробрасываем с нашего докер сервера внутрь контейнера
      - 5432:5432
    volumes:                                      # Папка, которую мы пробросим с докер сервера внутрь контейнера
      - ./pg_data:/var/lib/postgresql/data/pgdata
    environment:                                  # Переменные среды
      POSTGRES_PASSWORD: ostrowskijea12!3!!       # Задаём пароль от пользователя postgres
      POSTGRES_DB: ostrowskijea-netology_db       # БД которая сразу же будет создана
      PGDATA: /var/lib/postgresql/data/pgdata     # Путь внутри контейнера, где будет папка pgdata
    networks:
      ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.2
    restart: always                               # Режим перезапуска контейнера. Контейнер всегда будет перезапускаться

  pgadmin:
    image: dpage/pgadmin4
    container_name: ostrowskijea-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ostrowskije@ilove-netology.com
      PGADMIN_DEFAULT_PASSWORD: 123456qwe123456
    ports:
      - "61231:80"
    networks:
      ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.3
    restart: always

  zabbix-server:
    image: zabbix/zabbix-server-pgsql
    links:
      - ostrowskijea-netology-db
    container_name: ostrowskijea-zabbix-netology
    environment:
      DB_SERVER_HOST: '172.22.0.2'
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ostrowskijea12!3!!
    ports:
      - "10051:10051"
    networks:
      ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.4
    restart: always

  zabbix_wgui:
    image: zabbix/zabbix-web-apache-pgsql
    links:
      - ostrowskijea-netology-db
      - zabbix-server
    container_name: ostrowskijea-netology_zabbix_frontend
    environment:
      DB_SERVER_HOST: '172.22.0.2'
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: ostrowskijea12!3!!
      ZBX_SERVER_HOST: "zabbix_wgui"
      PHP_TZ: "Europe/Moscow"
    ports:
      - "80:8080"
      - "443:8443"
    networks:
       ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.5
    restart: always

networks:
  ostrowskijea-my-netology-hw:
    driver: bridge
    ipam:
      config:
      - subnet: 172.22.0.0/24

```

# Docker 3

Без докера имеем:
- Проблемы с совместимость
- Проблемы зависимости
- Длительная настройка среды
- Разные среды (Разработка, тестирование, продакшн)

Основное назначение докер - контейнеризация приложений

Виртуальная машина в отличии от докера потребляет больше ресурсов, занимает больше места, дольше грузится, 

Docker образ это пакет или шаблон аналогичной шаблону виртуальной машины

Контейнер - запущенный образ
```
sudo docker run docker/whalesay cowsay Hi, JooS!
```
```
docker run alpine
docker run -it alpine sh
docker ps
docker run -d apline sleep 20
docker attach <container id / name>
docker ps -a
docker stop <container id / name>
docker rm <container id / name>
docker rm $(docker ps -aq)
docker pull nginx
docker exec <container id / name> cat /etc/nginx/nginx.conf
```
docker run
```
docker run reddis
docker run reddis:6.0.9
-t - terminal
-i - interactive
docker run -it rotorocloud/prompt-docker - позволит связать консоль контейнера с нашей и ввести значение
echo Joos | docker run -i rotorocloud/prompt-docker - подставить значение  автоматом
-p - проброс портов
docker run -p 80:5000 rotorocloud/webapp - проброс порта
-v - volume mapping - директория для хранения
docker run -v /opt/data:/var/lib/mysql mysql - директория для сохранения данных
docker inspect <container id / name>
docker logs <container id / name>
```
```
-d - detach - запуск контейнера в фоновом режиме
docker run -d apline sleep 20
docker attach <container id / name> - присоединиться к контейнету
docker stop <container id / name> - останавливаем контейнер
docker run mingrammer/flog flog -d 1 -500 - контейнер гененирует события 500 сек и выводит через 1 сек
docker run jenkins/jenkins:lte-alpine - ставим дженкинс контейнер - доступ только по внутреннему адресу конейнера (и так как обысно сеть - мост, то можно зайти с хоста)
docker run -p 8080:8080 jenkins/jenkins:lte-alpine - пробрасываем порт и получаем доступ по адресу хоста
- docker inspect <container id / name> - появляется PortBindings - указывает какие порты и куда проброшены
docker run -p 8080:8080 -v /home/joos:/var/jenkins_home -u root jenkins/jenkins:lte-alpine - добавляем том и запускаем от рута
```
**Docker image - Docker file**

Пример надо
1. OS Ubuntu
2. Обвновить apt репо
3. Установить зависимости apt
4. Установить зависимости pip
5. Скопировать код в /opt
6. Запустить с параметром 'flask'
```Dockerfile
FROM ubuntu - назначаем базовый образ
RUN apt-get update
RUN apt-get install -y python3 python3-pip - настраиваем зависимости
RUN pip3 install flask - устанавливаем нужные версии, бибилиотеки
COPY app.py /opt/app.py - копируем исходный код
ENTRYPOINT FLASK_APP=/opt/app.py flask run --host=0.0.0.0 --port=5000 - указывает точку входа
```
**Dockerfile**

ИНСТРУКЦИЯ - АРГУМЕНТ
```
docker build . -t rotoro/webapp - собирает Dockerfile
docker push rotorocloud/webapp
docker history rotorocloud/webapp - смотрим слои
```
Докер собирает все слоями, при пересборке берет уже готовые слои из кэша

export DOCKER_HOST=IP_Adress удаленного сервера - переключаем  докер-консоль на удаленный сервер

cat > app.py - Пишем в файл
```
код
Ctrl + C
```
```
docker build . - собираем образ
dicker tag <container id> rotorocloud/webapp:ubuntu - даем имя и тег образу
docker login
dovker push rotorocloud/webapp:ubuntu - грузим образ в докер хаб
```
export DOCKER_HOST= - возвращаем стандартный (локальный) докер хост

**Переменные**

**-e - задает переменную**
```
docker run -e ROCKET_SIZE=big rotorocloud/simple-webapp-rockets
docker run -e ROCKET_SIZE=small rotorocloud/simple-webapp-rockets
```
docker inspect <container id / name> - в разделе "Env" покажет укзанные переменные

CMD sleep 5 - указываем команду запуска
```
FROM ubuntu
CMD sleep 10
```
docker build . -t ubuntu-sleeper

= docker run ubuntu-sleeper **sleep 20** - при запуске с CMD можем поменять команду
```
FROM ubuntu
ENTRYPOINT ["sleep"]
```
docker build . -t ubuntu-sleeper2 - команда при старте **sleep**

docker run ubuntu-sleeper2 **10** - при запуске можем только добавить в команду

если не задать параметр то будет ошибка - missing operand
```
FROM ubuntu
ENTRYPOINT ["sleep"]
CMD sleep 10
```
можно объединить и тогда ENTRYPOINT возмет значение из CMD

docker run --entrypoint super-sleep ubuntu-sleeper 10 - заменим команду на super-sleep 10

**Docker Compose**

Пример
1. voting.app - python
2. in-memory DB - redis
3. worker - NET
4. db - postgresql
5. result-app - nodd
```
docker run -d --name=redis redis
docker run -d --name=db postgres:9.4
docker run -d --name=vote -p 5000:80 --link redis:redis voting-app
docker run -d --name=result -p 5001:80 --link db:db result-app
docker run -d --name=worker --link db:db --link redis:redis worker
```
--link - вносит запись в /etc/hosts - ip хост - устаревшая конструкция - надо использовать netwoks
```docker-compose.yml
redis:
  image: redis
db:
  image: postgres:9.4
vote:
  image: dockersamples/voting-app # - если репозитория нет то - buld: ./vote
  ports:
    - 5000:80
  links:
    - redis #(=redis:redis)
result:
  image: dockersamples/result-app  # -  buld: ./result (папка с dockerfile и зависимостями)
  ports:
    - 5001:80
  links:
    - db #(=db:db)
worker:
  image: dockersamples/worker  # -  buld: ./worker
  links:
    - db
    - redis
```
docker-compose up

**version 1** - много ограничений (например нельзя развернуть в разных сетях кроме мостовой, нельзя указать зависимости - например поднять redis посде db)

**version 2** - links не нужен - все что в одном services будет объединено в сеть, появился depends_on

**version 3** - схожа с ver 2, отличие появления оркестрации - docker swarm и работы нескольких хостов
```
version 2 (3)
services:
  redis:
    image: redis
  db:
    image: postgres:9.4
  vote:
    image: dockersamples/voting-app
    ports:
      - 5000:80
    depends_on:
      - redis
```
Разделяем сети
```
version 2 (3)
services:
  redis:
    image: redis
    networks:
      - backend
  db:
    image: postgres:9.4
    networks:
      - backend
  vote:
    image: dockersamples/voting-app
    ports:
      - 5000:80
    networks:
      - frontend
      - backend
  result:
    image: dockersamples/result-app
    ports:
      - 5001:80
    networks:
      - frontend
      - backend
  worker:
    image: dockersamples/worker
    networks:
      - backend
networks:
  frontend:
  backend:
```
```
docker-compose up -d
docker-compose down
docker-compose ps
docker-compose logs
docker-compose up -d --scale vote=3
```

**Docker Engine**

Docker Host = Docker deamon + REST API + Docker CLI

Докер демон это фоновый процесс который управляет объектами докер такими как образы, контейнеры, тома и сети

API Server поддерживает API которой программы могут использовать для общения с демоном и предоставления инструкций

Docker CLI это утилита командной строки которую мы использовали до сих пор для выполнения таких действий как запуск остановка контейнеров уничтожения образов и так далее она использует вызовы REST API для взаимодействия с демоном докер
```
docker -H=remote-docker-engine:2375 - можно со своего компа присоединиться к другому серверу для работы с докером
docker -H=10.10.10.1:2375 run nginx
```
Докер используют пространство имен **namespace** для изоляции идентификаторов процессов рабочего пространства, подключение к сети, система разделения времени. Unix процессы контейнера выполняются в их собственном пространстве имен тем самым обеспечивая изоляцию с другими процессами

**Cgroups** - способ ограничить объем центрального процессора или памяти который может использовать контейнер докер используют контрольные группы си groups чтобы ограничить количество аппаратных ресурсов выделяемых каждому
```
docker run --cpus=.5 nginx
docker run --memory=100m nginx
```

**Хранилища**

В контейнере - /var/lib/docker
- /overlay2  /containers  /image  /volumes - здесь докер по умолчанию хранит все свои данные

Докер все пишет по слоям, берет существующие слои из кэша.

Есть слои образа, есть слой контейнера - все изменения при работающей контейнере попадают в слой контейнера, который живет пока жив контейнер.

Мы можем изменить файл внутри контейнера, но прежде чем я сохраню измененный файл докер автоматически создаст копию файла на уровне чтения и записи и затем я буду изменять и работать уже с другой версии файла которая будет находиться в другом слое, слое контейнера. И чтение и записи все будущие изменения будут внесены в эту копию файла на уровне чтение записи, это называются механизмом копирования при записи copy on write - слои образа доступны только для чтения это означает что файлы в этих слоях не будут изменены на самом деле, образ будет оставаться неизменным все время пока ты не перестроишь его с помощью команды docker build

Том - Volume
```
docker volume create data_volume - создаем папку в /var/lib/docker/volumes
без это коменды, докер создаст автоматом и подключит такую папку при следующей команде -
docker run -v data_volume:/var/lib/mysql mysql - volume mount - монтируем том внутрь контейнера (создаем если не создан)
docker run -v /data/mysql:/var/lib/mysql mysql - bind mount - подключаем к определенной директории
docker run --mount type=bind,source=./data/mysql,target=/var/lib/mysql mysql mysql - новый стиль, продвигает Docker
```
**Storaga drivers** - драйвер и хранилища для обеспечения многоуровневой архитектуры - несет ответственность за выполнение всех операций - сохранение многоуровневой архитектуры, создание слоев с возможностью записи, перемещение файлов между слоями, для возможности копирования и записи и так далее.

**Некоторые драйверы хранения** (Выбор зависит от исполоьзуемой ос.)
- aufs
- btrfs
- zfs
- device mapper
- overlay
- overlay2
- fuse overlayfs
```
docker info - покажет Storage driver
```
Докер сам постараются выбрать лучший драйвер хранилища который доступен в конкретной операционной системе но это не всегда работает хорошо в случае проблем нужно настраивать руками

**Сети в Docker**

Сети по умолчанию
```
docker run webapp
```
- Bridge - частная внетренняя сеть созданная докер на хосте, контейнеры подключены к ней по умолчанию (172.17.0.1)
```
docker run webapp --network=none
```
- None - контейнеры не являются членами сети и не имеют у другим контейнетам и узлам
```
docker run webapp --network=host
```
- Host - прямое связывание контейнера с сетью хоста, убирает сетевую изоляцию между хостом и контейнером - контейнер использует все сетевые ресурсы своего хоста
- Overlay - для нагрузок связанных с оркестрацией, адаптирован для работы одной сети на нескольких узлах
- Macvlan - связана с докеризацией нагрузки с виртуальными машинами, полностью эмулирует физический хост части сети
```
docker network create --driver bridge --subnet 182.18.0.0/16 my-network - создаем свою сеть
docker network ls
```
Docker имеет встроенный dns сервер (127.0.0.11), который разрешает имена контейнеров

**Docker Image**

docker run nginx

nginx = image:docker.io/nginx/nginx
- docker.io - Registry (DockerHub)
- nginx - User/Account
- nginx - Image/Repository

gcr.io - google
```
docker login private-registry.io - логин в свой репозиторий
docker run private-registry.io/app/internal-app - запуск из своего репозитория
```
Создаем и используем свой локальный репозиторий
```
docker run -d -p 5000:5000 --name registry registry:2
docker image tag my-image localhost:5000/my-image
docker push localhost:5000/my-image
docker pull localhost:5000/my-image
```
Для взаимодействия по сети нужны сетрификаты

**Kubernetes**
```
kubectl create deployment node --image=node:v1 - запускаем нужное
kubectl scale --replicas=9 node - масштабируем
kubectl scale --replicas=18 node - настраиваем, можем сделать зависимость от нагрузки
kubectl set image deployment node --image=node:v2 - обновление
kubectl rollout undo deployment node - откатываем обновления
```
Кластер - набор сгруппированных узлов, нод

Ноды - машина на которой установлен кубернетес

Worker Node - узел на котром кубернетес будет запускать контейнеры с нагрузкой

Мастер нода - нода сконфигурированная как мастер - наблюдает за состоянием других нод и ответственна за оркестрацию контейнеров на воркер нодах.

Компоненты:
- API SERVER - frontend - единый интерфейс Kubernetes, все общаются с api server 
- CONTAINER RUNTIME - среда выполнения контейнера - базовое по используется для запуска контейнеров
- CONTROLLER - мозг оркестрации, смотрят за состоянием нод, контейнеров, endpoint-ов и ответственны за реакцию за события на нодах. Принимают решения о создании новых контейнеров.
- SCHEDULER - ответственнен за распределение работ или контейнеров между нодами, ожидает появления контейнера, чтобы назначить его выполнение на ноду
- Служба KUBELET - агент который работает на каждом узле кластера, агент отвечает за то чтобы контейнеры работали на узлах должным образом
- Служба ETCD - хранилище ключ-значение, распределенная надежная БД используемая kubernetes для хранения информации нужной для управления кластера

kubectl (kubecontrol) - используется для развертывания и управления приложениями в кластере кубернетес, для получения информации о кластере, получения состояния других нод в кластере
```
kubectl run hello-minikube - развертывание приложения в кластере
kubectl cluster-info - информация о кластере
kubrctl get nodes - вывод списка всех узлов в кластере
```
